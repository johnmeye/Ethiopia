{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethiopia Mapping Section\n",
    "\n",
    "This Python Jupyter file is to calculate and build out the requirements for the Ethiopian design. It could be possible to do this in Excel as well; but this way we have an ability to reference and redesign as per the changing requirements.\n",
    "\n",
    "First Step is to collect the information; I have a Github account under my username (johnmeye) which i will reference from the file so that anyone who uses Conda/Jupyter will be able to get the files. For any challenges reach out to me on teams or by email (johnmeye@cisco.com)\n",
    "\n",
    "## Second Revision\n",
    "\n",
    "This is the second revision of this file as there was a business case change from Vodacom. As a result I'm rewriting this to make it clearer and smoother to calculate the required output. \n",
    "\n",
    "## Inputs\n",
    "\n",
    "The following are the inputs to this file received from Vodacom.\n",
    "1. Site specifications \n",
    "2. Site locations\n",
    "2. Business case \n",
    "3. Consumption assumption of users\n",
    "\n",
    "## Outputs \n",
    "\n",
    "The following are the expected outputs of this file:\n",
    "1. BoM for sites in catagories of:\n",
    "\n",
    "    a. POC1\n",
    "    \n",
    "    b. POC2\n",
    "    \n",
    "    c. POC3\n",
    "    \n",
    "    d. Access\n",
    "    \n",
    "    e. Peering\n",
    "    \n",
    "    \n",
    "2. BoM's will be in the correct format for CCW upload to allow for quick creation of the total costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#For the Map Plotting\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "#For the Inline display of figures.\n",
    "from IPython.display import HTML\n",
    "from IPython.display import IFrame\n",
    "\n",
    "#For the Widgets\n",
    "#Importing Widgets to allow for the changing of variables on the fly as questions are asked.\n",
    "import ipywidgets as widgets \n",
    "\n",
    "#Fuzzy Matching:\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data \n",
    "\n",
    "## Geographical Data\n",
    "\n",
    "This file below is from the Ethiopian files available from the database on the following site:\n",
    "https://data.humdata.org/dataset/ethiopia-population-data-_-admin-level-0-3\n",
    "\n",
    "This site has both topography and the Level 0-3 admin data on the population levels per county/province. Vodacom only provided at Admin 1 (Provincial level) for this RFQ; but we are able to go more in depth to try and work out if there is any additional information we can use to strengthen our position.\n",
    "\n",
    "The following section will pull that information from my Github; so that you don't have to fetch it yourself. Then load it as a JSON file into the DB, which you can see are Polygon type files with GPS coordinates which mark out the different layers/levels in the country. \n",
    "\n",
    "If needed you can pull the information from the GeoJSON files as well, but i did include the boundaries data as a dataframe too. \n",
    "Example: counties3[\"features\"][0]['properties'] #Just a sample on how to pull out specific information from the Counties json Files.\n",
    "\n",
    "## Admin Level Data\n",
    "\n",
    "As mentioned above; there is both Geo and Admin data; this information matches the information against some paramater; since the file is nicely structured according to standards we will stick to the humanitarian markings. \n",
    "\n",
    "Below i read the information from different levels into the variables for Admin1-3 so that we are able to use them to draw choropleth maps of the country. \n",
    "\n",
    "Once read into memory; it is possible to find matches against the specific parameters in both the GeoJSON and the Admin files. So i run a few sample commands to view what the data looks like. \n",
    "\n",
    "## Vodacom Sites Data\n",
    "Vodacom has provided the Ethiopia site numbers, and the expected by year and by type, although the Vodacom breaks it down by height and rooftop; this might not be necessary from our point of view and should not impact the way we calculate this. \n",
    "\n",
    "For this we will need to figure out how to define rural/urban and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*Geographical Data*\n",
    "#Pull the Data I stored in my Github account for the analysis.\n",
    "\n",
    "with urlopen('https://github.com/johnmeye/Ethiopia/raw/master/Ethiopia_JSON/eth_admbnda_adm1_csa_bofed_20190827.json') as response:\n",
    "    counties1 = json.load(response)\n",
    "    \n",
    "with urlopen('https://github.com/johnmeye/Ethiopia/raw/master/Ethiopia_JSON/eth_admbnda_adm2_csa_bofed_20190827.json') as response:\n",
    "    counties2 = json.load(response)\n",
    "    \n",
    "with urlopen('https://github.com/johnmeye/Ethiopia/raw/master/Ethiopia_JSON/eth_admbnda_adm3_csa_bofed_20190827.json') as response:\n",
    "    counties3 = json.load(response)\n",
    "\n",
    "#*Feature Data* \n",
    "#This data is available in the JSON files but its easier to manage from a tableset so i have pulled this below as well.\n",
    "#Feature data is area, coordinates and naming conventions of each province/suburb/district in ethiopia.\n",
    "    \n",
    "Boundaries_Data1 = pd.read_excel(\"https://github.com/johnmeye/Ethiopia/raw/master/eth_adminboundaries_tabulardata.xlsx\",\n",
    "                  sheet_name='Admin1')\n",
    "\n",
    "Boundaries_Data2 = pd.read_excel(\"https://github.com/johnmeye/Ethiopia/raw/master/eth_adminboundaries_tabulardata.xlsx\",\n",
    "                    sheet_name='Admin2')\n",
    "\n",
    "Boundaries_Data3 = pd.read_excel(\"https://github.com/johnmeye/Ethiopia/raw/master/eth_adminboundaries_tabulardata.xlsx\",\n",
    "                    sheet_name='Admin3')\n",
    "\n",
    "\n",
    "#*Admin Level Data*\n",
    "\n",
    "Admin1 = pd.read_excel(\"https://github.com/johnmeye/Ethiopia/raw/master/ethiopia-population-data-_-admin-level-0-3.xlsx\",\n",
    "                   dtype={\"admin1Pcode\": str},\n",
    "                   skiprows=[1],\n",
    "                   sheet_name='Admin1')\n",
    "\n",
    "Admin2 = pd.read_excel(\"https://github.com/johnmeye/Ethiopia/raw/master/ethiopia-population-data-_-admin-level-0-3.xlsx\",\n",
    "                   dtype={\"admin1Pcode\": str},\n",
    "                   skiprows=[1],\n",
    "                   sheet_name='Admin2')\n",
    "\n",
    "Admin3 = pd.read_excel(\"https://github.com/johnmeye/Ethiopia/raw/master/ethiopia-population-data-_-admin-level-0-3.xlsx\",\n",
    "                   dtype={\"admin1Pcode\": str},\n",
    "                   skiprows=[1],\n",
    "                   sheet_name='Admin3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site information input\n",
    "\n",
    "The input file from Vodacom gives the sites by province and by year for the install. They have predefined what a site type is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sites = pd.read_excel(\"https://github.com/johnmeye/Ethiopia/raw/master/Wakanda%20RFP_Updated%20Site%2BTraffic%20Inputs_04_Sep_2020.xlsx\",\n",
    "                   sheet_name='Site Nominals')\n",
    "Sites['REGION'] = Sites['REGION'].str.title()\n",
    "Sites['WOREDA'] = Sites['WOREDA'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10539 entries, 0 to 10538\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Longitude           10539 non-null  float64\n",
      " 1   Latitude            10539 non-null  float64\n",
      " 2   REGION              10539 non-null  object \n",
      " 3   WOREDA              10539 non-null  object \n",
      " 4   Woreda (alt name)   10539 non-null  object \n",
      " 5   Clutter Class Name  10539 non-null  object \n",
      " 6   Antenna  Height     10539 non-null  int64  \n",
      " 7   TOWER TYPE          10539 non-null  object \n",
      " 8   SITE TYPE           10539 non-null  object \n",
      " 9   TECHNOLOGY          10539 non-null  object \n",
      " 10  On-Air Year         10539 non-null  object \n",
      "dtypes: float64(2), int64(1), object(8)\n",
      "memory usage: 905.8+ KB\n"
     ]
    }
   ],
   "source": [
    "Sites.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "NamedSites1 = pd.merge(Sites, Admin3[['admin3Name_en', 'admin3Pcode']],how='outer', left_on =['WOREDA'], right_on=['admin3Name_en'])\n",
    "NaN_Sites2 = NamedSites1[NamedSites1['admin3Pcode'].isnull()]\n",
    "NamedSites1 = NamedSites1[NamedSites1['admin3Pcode'].notna()]\n",
    "NamedSites1 = NamedSites1[NamedSites1['REGION'].notna()]\n",
    "NaN_Sites2 = NaN_Sites2.drop(['admin3Name_en', 'admin3Pcode'], axis=1)\n",
    "NamedSites2 = pd.merge(NaN_Sites2, Admin3[['admin3Name_en', 'admin3Pcode']],how='left', left_on =['Woreda (alt name)'], right_on=['admin3Name_en'])\n",
    "NaN_Sites2 = NamedSites2[NamedSites2['admin3Pcode'].isnull()]\n",
    "NamedSites2 = NamedSites2[NamedSites2['admin3Pcode'].notna()]\n",
    "NamedSites3 = pd.merge(NaN_Sites2, Admin3[['admin3Name_en', 'admin3Pcode']],how='left', left_on =['Woreda (alt name)'], right_on=['admin3Name_en'])\n",
    "\n",
    "frames = [NamedSites1, NamedSites2]\n",
    "result = pd.concat(frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker(wrong_options,correct_options):\n",
    "    names_array=[]\n",
    "    ratio_array=[]\n",
    "    for wrong_option in wrong_options:\n",
    "        if wrong_option in correct_options:\n",
    "            names_array.append(wrong_option)\n",
    "            ratio_array.append('100')\n",
    "        else:\n",
    "            x=process.extractOne(wrong_option,correct_options,scorer=fuzz.token_set_ratio)\n",
    "            names_array.append(x[0])\n",
    "            ratio_array.append(x[1])\n",
    "    return names_array,ratio_array\n",
    "\n",
    "str2Match = NaN_Sites2['WOREDA'].tolist()\n",
    "strOptions =Admin3['admin3Name_en'].tolist()\n",
    "\n",
    "name_match,ratio_match=checker(str2Match,strOptions)\n",
    "df1 = pd.DataFrame()\n",
    "df1['old_names']=pd.Series(str2Match)\n",
    "df1['correct_names']=pd.Series(name_match)\n",
    "df1['correct_ratio']=pd.Series(ratio_match)\n",
    "df1.to_excel('matched_names.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NamedSites1.to_excel(\"output1.xlsx\")\n",
    "NamedSites2.to_excel(\"output2.xlsx\")\n",
    "NaN_Sites2.to_excel(\"output3.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
